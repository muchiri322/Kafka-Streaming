{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da662743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "cities = [\"Nairobi\", \"Niger\", \"Pretoria\", \"Lusaka\", \"Lagos\", \"Cairo\"]\n",
    "API_KEY = \"8f7c039d18fc20fade3dcca7a8fe1693\"\n",
    "KAFKA_TOPIC = \"weather_data\"\n",
    "KAFKA_SERVER = \"localhost:9092\"\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=[KAFKA_SERVER],\n",
    "    value_serializer=lambda v: json.dumps(v).encode(\"utf-8\")\n",
    ")\n",
    "\n",
    "while True:\n",
    "    for city in cities:\n",
    "        try:\n",
    "            url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_KEY}&units=metric\"\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            data[\"city\"] = city\n",
    "            producer.send(KAFKA_TOPIC, value=data)\n",
    "            print(f\"Sent weather data for {city}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching/sending data for {city}: {e}\")\n",
    "    time.sleep(480))  # wait 8 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f53afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaWeatherConsumer\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# Define schema for weather JSON\n",
    "schema = StructType().add(\"name\", StringType()).add(\"main\", StructType().add(\"temp\", DoubleType()))\n",
    "\n",
    "# Read from Kafka\n",
    "df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"weather\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "# Parse the value from Kafka\n",
    "weather_df = df.selectExpr(\"CAST(value AS STRING) as json\") \\\n",
    "    .select(from_json(col(\"json\"), schema).alias(\"data\")) \\\n",
    "    .select(\"data.name\", \"data.main.temp\")\n",
    "\n",
    "# Write to console\n",
    "query = weather_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
